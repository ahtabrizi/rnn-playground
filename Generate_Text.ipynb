{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generate Text.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_ntxLZAgKZH",
        "colab_type": "code",
        "outputId": "0f36cb95-6972-4ba0-9525-2675888aeac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/\"My Drive\"/textgen\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/textgen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo4hwd1ggkJu",
        "colab_type": "code",
        "outputId": "f5ed9af0-57ac-4df7-d645-8bdf41e8e1ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from keras.layers import LSTM, Dense\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bc6FhW1grIX",
        "colab_type": "code",
        "outputId": "2bb98338-cbf8-4743-afa1-5b3594726d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "path = get_file(\"shakespear.txt\", 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "\n",
        "    # 'nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8C2Gzhih07y",
        "colab_type": "code",
        "outputId": "9d20d26d-e7f2-4ec6-a8f2-95fa3ec5050f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "with io.open(path, encoding='utf-8') as f: \n",
        "  text = f.read().lower()\n",
        "\n",
        "print(\"Lenght of text: {} characters.\".format(len(text)))\n",
        "print(text[:300])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lenght of text: 1115394 characters.\n",
            "first citizen:\n",
            "before we proceed any further, hear me speak.\n",
            "\n",
            "all:\n",
            "speak, speak.\n",
            "\n",
            "first citizen:\n",
            "you are all resolved rather to die than to famish?\n",
            "\n",
            "all:\n",
            "resolved. resolved.\n",
            "\n",
            "first citizen:\n",
            "first, you know caius marcius is chief enemy to the people.\n",
            "\n",
            "all:\n",
            "we know't, we know't.\n",
            "\n",
            "first citizen:\n",
            "let us\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrQQaXjalmll",
        "colab_type": "code",
        "outputId": "c148aa18-9f43-4a41-cc85-78512c13fd20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('{} unique chars'.format(len(chars)))\n",
        "print(chars)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39 unique chars\n",
            "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H00nh77wmOyN",
        "colab_type": "code",
        "outputId": "65cd7e71-be6c-4b3a-fa62-2e78621ab530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "char_index = dict((c, i) for i, c in enumerate(chars))\n",
        "index_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "text_as_int = np.array([char_index[c] for c in text])\n",
        "\n",
        "print(\"{} ------> {}\".format(repr(text[:20]), text_as_int[:20]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'first citizen:\\nbefor' ------> [18 21 30 31 32  1 15 21 32 21 38 17 26 10  0 14 17 18 27 30]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bSc7RGim13w",
        "colab_type": "code",
        "outputId": "4643c83d-12af-4480-bc34-86d0a564b6f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_len = 128\n",
        "step = 5\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - max_len, step):\n",
        "  sentences.append(text[i: i + max_len])\n",
        "  next_chars.append(text[i + max_len])\n",
        "\n",
        "print('Number of sentences: ', len(sentences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences:  223054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVtHQa0OpxZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.zeros((len(sentences), max_len, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, char_index[char]] = 1\n",
        "  y[i, char_index[next_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ykdo1USrYnk",
        "colab_type": "code",
        "outputId": "3ca2ab27-5973-4a7a-fe27-54ab9de3e42e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False  True False ... False False False]]\n",
            "\n",
            " [[False  True False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False  True False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False  True]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False  True False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False  True False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False  True False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [ True False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]]\n",
            "[[False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " ...\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [ True False False ... False False False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUHokhBzrc-K",
        "colab_type": "code",
        "outputId": "428d9e12-58eb-4378-aef9-f2c5b16348ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# build model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(max_len, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpLMKgFPsUK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(pred) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6QTlCuhvR4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random \n",
        "def on_epoch_end(epoch, _):\n",
        "  textfile = open('epochOutput.txt', 'a')\n",
        "  print(\"--------Genrating text after epoch: {} \".format(epoch), file=texfile )\n",
        "\n",
        "  start_index = rando.randint(0, len(text) - max_len - 1)\n",
        "\n",
        "  for temp in [0.2, 0.5, 1, 1.2]:\n",
        "    print(\"-------Temperature:\", temp, file=textfile)\n",
        "\n",
        "    sentence = text[start_index: start_index + max_len]\n",
        "    generated = ''\n",
        "    generated += sentence\n",
        "\n",
        "    print(\"------Generated with sentence: '\", sentence + \"'\", file=textfile)\n",
        "\n",
        "\n",
        "    for i in range(400):\n",
        "      x_pred = np.zeros((1, max_len, len(char)))\n",
        "      for t, char in enumerate(sentence):\n",
        "        x_pred[0, t, char_index[char]] = 1\n",
        "\n",
        "      preds = model.predict(x_pred)[0]\n",
        "      next_index = sample(preds, temp)\n",
        "      next_char = index_char[next_index]\n",
        "\n",
        "      sentence = sentence[1:] + next_char\n",
        "\n",
        "      print(next_char, file=textfile, end='')\n",
        "    print('\\n', file=textfile)\n",
        "  print('\\n' + '='*30, file=textfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqC5if3tyVqo",
        "colab_type": "code",
        "outputId": "ae47488f-b3ce-415c-9dd3-cd0688c45431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs = 30,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " 20864/223054 [=>............................] - ETA: 7:13 - loss: 2.6507"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-13-dbeb25711291>\", line 8, in <module>\n",
            "    callbacks=[print_callback])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1178, in fit\n",
            "    validation_freq=validation_freq)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\", line 204, in fit_loop\n",
            "    outs = fit_function(ins_batch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2979, in __call__\n",
            "    return self._call(inputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2937, in _call\n",
            "    fetched = self._callable_fn(*array_vals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n",
            "    run_metadata_ptr)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
            "    module = self._load()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 44, in _load\n",
            "    module = _importlib.import_module(self.__name__)\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/__init__.py\", line 90, in <module>\n",
            "    from tensorflow.contrib import tensor_forest\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/tensor_forest/__init__.py\", line 21, in <module>\n",
            "    from tensorflow.contrib.tensor_forest.client import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/tensor_forest/__init__.py\", line 21, in <module>\n",
            "    from tensorflow.contrib.tensor_forest.client import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/tensor_forest/client/__init__.py\", line 22, in <module>\n",
            "    from tensorflow.contrib.tensor_forest.client import random_forest\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/tensor_forest/client/random_forest.py\", line 27, in <module>\n",
            "    from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/tensor_forest/python/__init__.py\", line 21, in <module>\n",
            "    from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/tensor_forest/python/tensor_forest.py\", line 30, in <module>\n",
            "    from tensorflow.contrib.tensor_forest.python.ops import model_ops\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/tensor_forest/python/ops/model_ops.py\", line 42, in <module>\n",
            "    resource_loader.get_path_to_datafile(\"_model_ops.so\"))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/util/loader.py\", line 56, in load_op_library\n",
            "    ret = load_library.load_op_library(path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/load_library.py\", line 61, in load_op_library\n",
            "    lib_handle = py_tf.TF_LoadLibrary(library_filename)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXUeR8YRy3Md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}